{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step1: Follow the paper and Shanza's code, we write functions to compute each entry for matrix T with a given eccentricity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import special\n",
    "from scipy import integrate\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "maxq = 10000 # initialize max period number\n",
    "\n",
    "semi_axes = pd.read_csv(\"e_and_semi_axes.txt\", sep = '\\t') # the file that contains the semi-axes associated with each eccentricity\n",
    "semi_axes.drop(\"Unnamed: 0\", axis = 1, inplace = True)\n",
    "\n",
    "def collision_period(q):\n",
    "    amplitudes = collision_amplitude(q)\n",
    "    a = semi_axes[str_e][0]\n",
    "    b = semi_axes[str_e][1]\n",
    "    result = []\n",
    "    for j in range(0,q):\n",
    "        result.append([a*math.sin(amplitudes[j]),-b*math.cos(amplitudes[j])])\n",
    "    return (result)\n",
    "\n",
    "def collision_amplitude(q):\n",
    "    \"\"\"\n",
    "    Returns an array of the q collision points relative to period q\n",
    "    \"\"\"\n",
    "\n",
    "    result = []\n",
    "    points = collision_pts[str(q).zfill(2)].dropna()\n",
    "    for j in range(0,q):\n",
    "        result.append(float(points[j]))\n",
    "    return (result)\n",
    "\n",
    "################### The following functions find the angle associated with each collision point #################################\n",
    "\n",
    "\n",
    "def find_vector1(u,v): # u is the earlier point, v is the next point/the point we are looking at\n",
    "    v1 = np.subtract(v,u)\n",
    "    mag_v1 = math.sqrt((v1[0]**2)+(v1[1]**2))\n",
    "    v1_unit = v1 / mag_v1\n",
    "    return (v1_unit)\n",
    "\n",
    "def find_tangent_vector(x,y,str_e):\n",
    "    a = semi_axes[str_e][0]\n",
    "    b = semi_axes[str_e][1]\n",
    "    y_prime = (b*x)/a\n",
    "    x_prime = -(a*y)/b\n",
    "    mag = np.sqrt(x_prime**2+y_prime**2)\n",
    "    y_tan = y_prime/mag\n",
    "    x_tan = x_prime/mag\n",
    "    return (x_tan, y_tan)\n",
    "\n",
    "def sinphi_lst(q, str_e):\n",
    "    '''Returns a list of sin(phi) for all point in a given periodic orbit'''\n",
    "    sinphi_list = []\n",
    "    for pt in collision_period(q):\n",
    "        v1_unit = tuple(find_vector1(pt, collision_period(q)[(collision_period(q).index(pt)-1)%q]))\n",
    "        v2_unit = find_tangent_vector(pt[0],pt[1],str_e)\n",
    "        cosphi = np.dot(v1_unit,v2_unit)\n",
    "        sinphi_list.append(np.sqrt(1-cosphi**2))\n",
    "    return(sinphi_list)\n",
    "\n",
    "################## The following functions find the lazutkin coordinate associated with each collision point ###########################\n",
    "\n",
    "def lazutkin_coordinate_analytic(amplitude,e):\n",
    "    return 0.25*(special.ellipkinc(amplitude,e**2)/special.ellipk(e**2)-1)\n",
    "\n",
    "def mu_analytic(amplitude,e):\n",
    "    return 2*special.ellipk(e**2)*np.sqrt((1-e**2)/(1-e**2*math.sin(amplitude)**2))\n",
    "\n",
    "\n",
    "############# Each entry of the matrix T ###########################\n",
    "\n",
    "def T_of_q_j(q,j,str_e,e):\n",
    "    '''T_q_j is a matrix, by varying q and j, you obtain an entry for that matrx.\n",
    "    Think of the q as the rows, while the j are the columns. Fixing q and j gives you one entry.\n",
    "    Fixing q and varying j will give you a row, fixing j and varying q will give you a column.\n",
    "    Make sure to keep this in mind when you use this function, you will have to make changes to the code accordingly\n",
    "    before you run this function.'''\n",
    "    k_sum = []\n",
    "    if q==1:\n",
    "        mu_k = mu_analytic(np.pi/2,e)\n",
    "        return 1./mu_k\n",
    "    col_pt = collision_period(q)\n",
    "    col_amp = collision_amplitude(q)\n",
    "    sinphi_list_q = sinphi_lst(q,str_e)\n",
    "\n",
    "    for k in range(q):\n",
    "        sinphi = sinphi_list_q[k]\n",
    "\n",
    "        laz_k = lazutkin_coordinate_analytic(col_amp[k],e)\n",
    "\n",
    "        mu_k = mu_analytic(col_amp[k],e)\n",
    "\n",
    "        sum_exp = sinphi*(np.cos(2*np.pi*j*laz_k)/mu_k)\n",
    "        k_sum.append(sum_exp)\n",
    "    return(sum(k_sum))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step2: Write the function lambda_marvizi_melrose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lambda_marvizi_melrose(j,str_e,e):\n",
    "    \"\"\"\n",
    "    This computes an approximate limit for q→∞ of T_qj\n",
    "    it computes the magic_q'th element of the vector\n",
    "\n",
    "    \"\"\"\n",
    "    if (j%2==1): # Ellipse has additional symmetry: every odd term is 0\n",
    "        return 0\n",
    "    magic_q=min(j+10,999)\n",
    "    q=j;\n",
    "    mmc=(q**2*T_of_q_j(q,j,str_e,e));\n",
    "    continuing=True\n",
    "    accord=0.000001\n",
    "    while continuing:\n",
    "        q=q+1;\n",
    "        mmc_new=(q**2*T_of_q_j(q,j,str_e,e));\n",
    "        continuing=(np.abs(mmc-mmc_new)<accord)\n",
    "    print (\"mmc:\",j,\" \",q,\" \",magic_q,\"   -   \",mmc_new)\n",
    "    return mmc_new\n",
    "# We probably need to justify the choice of magic_q\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step3: Write functions to compute the reduced matrix T for each eccentricity using vectorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from scipy import special\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# ---------------------------\n",
    "# Precompute Functions\n",
    "# ---------------------------\n",
    "\n",
    "def lazutkin_coordinate_analytic_vec(amplitudes, e):\n",
    "    \"\"\"Vectorized version for lazutkin_coordinate_analytic.\"\"\"\n",
    "    # ellipkinc and ellipk support array inputs in recent SciPy versions.\n",
    "    # If not, consider using np.vectorize.\n",
    "    return 0.25*(special.ellipkinc(amplitudes, e**2)/special.ellipk(e**2)-1)\n",
    "\n",
    "def mu_analytic_vec(amplitudes, e):\n",
    "    \"\"\"Vectorized version for mu_analytic.\"\"\"\n",
    "    # Ensure vectorized operations:\n",
    "    return 2*special.ellipk(e**2)*np.sqrt((1-e**2)/(1-e**2*np.sin(amplitudes)**2))\n",
    "\n",
    "def find_tangent_vector_vec(x, y, a, b):\n",
    "    \"\"\"Vectorized tangent vector computation for arrays x, y.\"\"\"\n",
    "    # x and y are arrays\n",
    "    y_prime = (b*x)/a\n",
    "    x_prime = -(a*y)/b\n",
    "    mag = np.sqrt(x_prime**2 + y_prime**2)\n",
    "    return x_prime/mag, y_prime/mag\n",
    "\n",
    "def sinphi_lst_vec(collision_points, a, b):\n",
    "    \"\"\"\n",
    "    Vectorized version of sinphi_lst for all q simultaneously.\n",
    "    collision_points is a list or dict: collision_points[q] = array of shape (q,2).\n",
    "    a,b are semi-axis lengths.\n",
    "    \"\"\"\n",
    "    # For each q, we want sinphi for q points.\n",
    "    # sinphi = sqrt(1 - cosphi^2), where cosphi = dot(v1_unit,v2_unit)\n",
    "    # v1_unit is direction from previous point to current\n",
    "    # v2_unit is tangent vector at current point\n",
    "\n",
    "    sinphi_dict = {}\n",
    "\n",
    "    for q, points in collision_points.items():\n",
    "        # points shape: (q,2)\n",
    "        # Compute the vectors from prev to current: v1 = p_(k-1)->p_k\n",
    "        # np.roll points by one to get previous points:\n",
    "        prev_points = np.roll(points, 1, axis=0)\n",
    "        v1 = points - prev_points\n",
    "        mag_v1 = np.linalg.norm(v1, axis=1, keepdims=True)\n",
    "        v1_unit = v1 / mag_v1\n",
    "\n",
    "        # Compute tangent vectors at each point\n",
    "        x, y = points[:,0], points[:,1]\n",
    "        x_tan, y_tan = find_tangent_vector_vec(x, y, a, b)\n",
    "        v2_unit = np.column_stack((x_tan, y_tan))\n",
    "\n",
    "        # cosphi = dot(v1_unit,v2_unit)\n",
    "        cosphi = np.sum(v1_unit*v2_unit, axis=1)\n",
    "        sinphi = np.sqrt(1 - cosphi**2)\n",
    "        sinphi_dict[q] = sinphi\n",
    "    return sinphi_dict\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Main Vectorization Approach\n",
    "# ---------------------------\n",
    "\n",
    "def precompute_for_all_q(max_q, str_e, e, collision_pts, semi_axes):\n",
    "    \"\"\"\n",
    "    Precompute all necessary arrays for T_of_q_j computations:\n",
    "    - collision amplitudes for each q\n",
    "    - collision points for each q\n",
    "    - sinphi for each q\n",
    "    - lazutkin coordinates and mu for each q\n",
    "    \"\"\"\n",
    "\n",
    "    a, b = semi_axes[str_e][0], semi_axes[str_e][1]\n",
    "\n",
    "    collision_amplitudes = {}\n",
    "    collision_points = {}\n",
    "    sinphi_dict = {}\n",
    "    laz_arr_dict = {}\n",
    "    mu_arr_dict = {}\n",
    "\n",
    "    # Precompute ellipk(e^2) once:\n",
    "    ellipk_e2 = special.ellipk(e**2)\n",
    "\n",
    "    for q in range(2, max_q+1):\n",
    "        q_str = str(q).zfill(2) \n",
    "        points_series = collision_pts[q_str].dropna()\n",
    "        col_amp = points_series.values.astype(float)\n",
    "    \n",
    "        # Store the amplitudes\n",
    "        collision_amplitudes[q] = col_amp\n",
    "    \n",
    "        x_vals = a * np.sin(col_amp)\n",
    "        y_vals = -b * np.cos(col_amp)\n",
    "        pts = np.column_stack((x_vals, y_vals))\n",
    "        collision_points[q] = pts\n",
    "\n",
    "\n",
    "    # Compute laz_arr and mu_arr as before, or do this later if you prefer.\n",
    "\n",
    "\n",
    "    # Compute sinphi for all q in a vectorized manner\n",
    "    sinphi_dict = sinphi_lst_vec(collision_points, a, b)\n",
    "\n",
    "    # Compute laz and mu arrays for all q\n",
    "    for q in range(2, max_q+1):\n",
    "        col_amp = collision_amplitudes[q]\n",
    "        # vectorized computations\n",
    "        laz_arr = lazutkin_coordinate_analytic_vec(col_amp, e)\n",
    "        mu_arr = mu_analytic_vec(col_amp, e)\n",
    "        laz_arr_dict[q] = laz_arr\n",
    "        mu_arr_dict[q] = mu_arr\n",
    "\n",
    "    return collision_points, sinphi_dict, laz_arr_dict, mu_arr_dict\n",
    "\n",
    "\n",
    "def reduced_T_qj_matrix_vectorized(max_q, max_j, str_e, e, lambda_MM, collision_points, sinphi_dict, laz_arr_dict, mu_arr_dict):\n",
    "    \"\"\"\n",
    "    Vectorized version of reduced_T_qj_matrix.\n",
    "    \"\"\"\n",
    "    # Ensure lambda_MM is a numpy array and pad if needed\n",
    "    lambda_MM = np.asarray(lambda_MM)\n",
    "    if len(lambda_MM) < max_j:\n",
    "        # pad with zeros\n",
    "        lambda_MM = np.pad(lambda_MM, (0, max_j - len(lambda_MM)), mode='constant')\n",
    "\n",
    "    reduced_matrix = np.zeros((max_q, max_j))\n",
    "    j_array = np.arange(1, max_j+1)\n",
    "\n",
    "    # For q=1, T_of_q_j is special:\n",
    "    mu_k = mu_analytic_vec(np.array([np.pi/2]), e)[0]\n",
    "    T_of_q1_j = 1./mu_k  # constant for all j\n",
    "    reduced_matrix[0, :] = T_of_q1_j - lambda_MM/(1**2)\n",
    "\n",
    "    # For q > 1:\n",
    "    for q in range(2, max_q+1):\n",
    "        sinphi = sinphi_dict[q]        # shape: (q,)\n",
    "        laz_arr = laz_arr_dict[q]      # shape: (q,)\n",
    "        mu_arr = mu_arr_dict[q]        # shape: (q,)\n",
    "\n",
    "        # Compute cos terms for all j at once:\n",
    "        # We want cos(2*pi*j*laz_k) for each j and k\n",
    "        # laz_arr[:, None] * j_array[None, :] gives a q x max_j array\n",
    "        argument = 2*np.pi*laz_arr[:, None]*j_array[None, :]\n",
    "        cos_mat = np.cos(argument)  # q x max_j\n",
    "\n",
    "        # sinphi, mu_arr must be broadcasted appropriately:\n",
    "        # T_qj = sum over k of (sinphi_k * cos(...)/mu_k)\n",
    "        # reshape sinphi and mu_arr for broadcasting:\n",
    "        numerator = sinphi / mu_arr  # q,\n",
    "        # Perform elementwise multiplication and sum over k:\n",
    "        T_qj_vector = np.sum((numerator[:, None] * cos_mat), axis=0)\n",
    "\n",
    "        reduced_matrix[q-1, :] = T_qj_vector - lambda_MM/(q**2)\n",
    "\n",
    "    return reduced_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step4: Now for a list of eccentricities, I will compute its associated reduceed_T_q_j.\n",
    "I will try to store the results in pickle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle  # Import the pickle module\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Assuming that you've defined or imported:\n",
    "# semi_axes (from \"e_and_semi_axes.txt\")\n",
    "# lambda_marvizi_melrose(j, str_e, e)\n",
    "# precompute_for_all_q(max_q, str_e, e, collision_pts, semi_axes)\n",
    "# reduced_T_qj_matrix_vectorized(max_q, max_j, str_e, e, lambda_MM, collision_points, sinphi_dict, laz_arr_dict, mu_arr_dict)\n",
    "\n",
    "########## Load Semi-Axes Data ##########\n",
    "semi_axes = pd.read_csv(\"e_and_semi_axes.txt\", sep='\\t')\n",
    "semi_axes.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
    "\n",
    "########## Some considerations in the interest of computational time ###########################\n",
    "\n",
    "magic_j = 750  # Arbitrary choice for truncating coefficients\n",
    "gamma = 3.5  # For faster decay\n",
    "arbitrary_accuracy = 100  # Controls accuracy of the computation\n",
    "\n",
    "sampled_e = [0.10]  # Eccentricities to consider\n",
    "lambda_MM_dict = {}  # Store Marvizi-Melrose coefficients for each eccentricity\n",
    "reduced_matrices = {}  # Store reduced matrices for each eccentricity\n",
    "\n",
    "max_q, max_j = 9999, 9999\n",
    "\n",
    "# First loop: Compute Marvizi-Melrose coefficients\n",
    "for e in sampled_e:\n",
    "    str_e = '%.2f' % e\n",
    "    print(f\"\\n---\\nProcessing eccentricity {e}\")\n",
    "    \n",
    "    # Load collision points\n",
    "    collision_pts = pd.read_csv(f\"all_periods_{str_e}e_col_amplitudes.txt\", sep='\\t')\n",
    "    collision_pts.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
    "    print(\"Collision points loaded\")\n",
    "    \n",
    "    \n",
    "    # Compute Marvizi-Melrose coefficients\n",
    "    lambda_MM = []\n",
    "    for j in np.arange(1, magic_j):\n",
    "        l = lambda_marvizi_melrose(j, str_e, e)\n",
    "        if (j % 2 == 0) and (abs(l) < 1e-7):\n",
    "            break\n",
    "        lambda_MM.append(l)\n",
    "\n",
    "    # After computing lambda_MM as in Code1:\n",
    "    for j in np.arange(len(lambda_MM) + 1, maxq * arbitrary_accuracy):\n",
    "        lambda_MM.append(0)\n",
    "\n",
    "    # Now truncate to match max_j since we're vectorizing a (max_q, max_j) matrix:\n",
    "    lambda_MM = np.array(lambda_MM)[:max_j]\n",
    "\n",
    "\n",
    "    lambda_MM_dict[e] = lambda_MM  # Store the adjusted coefficients\n",
    "\n",
    "    print(f\"Cached Marvizi-Melrose coefficients for eccentricity {e}\")\n",
    "\n",
    "# Second loop: Compute reduced matrices using vectorization\n",
    "for e in sampled_e:\n",
    "    str_e = '%.2f' % e\n",
    "    print(f\"Processing reduced matrix for eccentricity {e}\")\n",
    "    \n",
    "    # Reload collision_pts for use in precomputation\n",
    "    collision_pts = pd.read_csv(f\"all_periods_{str_e}e_col_amplitudes.txt\", sep='\\t')\n",
    "    collision_pts.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
    "    \n",
    "    # Precompute all necessary values for vectorized computations\n",
    "    collision_points, sinphi_dict, laz_arr_dict, mu_arr_dict = precompute_for_all_q(\n",
    "        max_q, str_e, e, collision_pts, semi_axes\n",
    "    )\n",
    "    \n",
    "    # Compute the reduced matrix using vectorization\n",
    "    reduced_matrix = reduced_T_qj_matrix_vectorized(\n",
    "        max_q, max_j, str_e, e, lambda_MM_dict[e], \n",
    "        collision_points, sinphi_dict, laz_arr_dict, mu_arr_dict\n",
    "    )\n",
    "    reduced_matrices[e] = reduced_matrix\n",
    "\n",
    "# Save the reduced matrices to a pickle file\n",
    "with open(\"reduced_matrices2.pkl\", \"wb\") as file:\n",
    "    pickle.dump(reduced_matrices, file)\n",
    "    print(\"Reduced matrices saved to reduced_matrices2.pkl\")\n",
    "\n",
    "# To load the results from the pickle file later on\n",
    "with open(\"reduced_matrices2.pkl\", \"rb\") as file:\n",
    "    loaded_matrices = pickle.load(file)\n",
    "    print(\"Reduced matrices loaded from reduced_matrices2.pkl\")\n",
    "\n",
    "# Example: Access the loaded matrix for eccentricity 0.1\n",
    "print(f\"\\nReduced matrix for eccentricity 0.1 (first 5 rows):\")\n",
    "print(loaded_matrices[0.1][:5, :5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REMARK: Notice for size 300 reduced matrix T with e=0.1, if we use these two different methods, we get slightly different results.\n",
    "\n",
    "Why These Differences Occur:\n",
    "\n",
    "Operation Order:\n",
    "Vectorization rearranges computation order. In previous code, computations occur in a strict, step-by-step manner, where each intermediate result is calculated and stored before the next step. In this part oof code, when you vectorize operations, many arithmetic operations happen together, possibly in a different sequence. Floating-point arithmetic is not strictly associative or distributive, so changing the order of additions and multiplications can lead to slight differences in the final decimal values.\n",
    "\n",
    "Floating-Point Precision:\n",
    "Even very small changes in intermediate rounding can cascade into small but noticeable differences at the 10^-12 or 10^-15 level. Both codes are correct, but because floating-point arithmetic isn’t exact, the numbers may differ slightly."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
